{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "AT5OogJVFbwu",
   "metadata": {
    "id": "AT5OogJVFbwu"
   },
   "source": [
    "# EasyVisa Project\n",
    "\n",
    "## Context:\n",
    "\n",
    "Business communities in the United States are facing high demand for human resources, but one of the constant challenges is identifying and attracting the right talent, which is perhaps the most important element in remaining competitive. Companies in the United States look for hard-working, talented, and qualified individuals both locally as well as abroad.\n",
    "\n",
    "The Immigration and Nationality Act (INA) of the US permits foreign workers to come to the United States to work on either a temporary or permanent basis. The act also protects US workers against adverse impacts on their wages or working conditions by ensuring US employers' compliance with statutory requirements when they hire foreign workers to fill workforce shortages. The immigration programs are administered by the Office of Foreign Labor Certification (OFLC).\n",
    "\n",
    "OFLC processes job certification applications for employers seeking to bring foreign workers into the United States and grants certifications in those cases where employers can demonstrate that there are not sufficient US workers available to perform the work at wages that meet or exceed the wage paid for the occupation in the area of intended employment.\n",
    "\n",
    "## Objective:\n",
    "\n",
    "In FY 2016, the OFLC processed 775,979 employer applications for 1,699,957 positions for temporary and permanent labor certifications. This was a nine percent increase in the overall number of processed applications from the previous year. The process of reviewing every case is becoming a tedious task as the number of applicants is increasing every year.\n",
    "\n",
    "The increasing number of applicants every year calls for a Machine Learning based solution that can help in shortlisting the candidates having higher chances of VISA approval. OFLC has hired your firm EasyVisa for data-driven solutions. You as a data scientist have to analyze the data provided and, with the help of a classification model:\n",
    "\n",
    "* Facilitate the process of visa approvals.\n",
    "* Recommend a suitable profile for the applicants for whom the visa should be certified or denied based on the drivers that significantly influence the case status. \n",
    "\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data contains the different attributes of the employee and the employer. The detailed data dictionary is given below.\n",
    "\n",
    "* case_id: ID of each visa application\n",
    "* continent: Information of continent the employee\n",
    "* education_of_employee: Information of education of the employee\n",
    "* has_job_experience: Does the employee has any job experience? Y= Yes; N = No\n",
    "* requires_job_training: Does the employee require any job training? Y = Yes; N = No \n",
    "* no_of_employees: Number of employees in the employer's company\n",
    "* yr_of_estab: Year in which the employer's company was established\n",
    "* region_of_employment: Information of foreign worker's intended region of employment in the US.\n",
    "* prevailing_wage:  Average wage paid to similarly employed workers in a specific occupation in the area of intended employment. The purpose of the prevailing wage is to ensure that the foreign worker is not underpaid compared to other workers offering the same or similar service in the same area of employment. \n",
    "* unit_of_wage: Unit of prevailing wage. Values include Hourly, Weekly, Monthly, and Yearly.\n",
    "* full_time_position: Is the position of work full-time? Y = Full Time Position; N = Part Time Position\n",
    "* case_status:  Flag indicating if the Visa was certified or denied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-island",
   "metadata": {
    "id": "dirty-island"
   },
   "source": [
    "## Importing necessary libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-still",
   "metadata": {
    "id": "statewide-still"
   },
   "outputs": [],
   "source": [
    "# this is a comprehensive list of dependencies in order to run linear regression and classification.\n",
    "%load_ext nb_black\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# To build model for prediction\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "##!pip install -U scikit-learn --user\n",
    "\n",
    "\n",
    "# To get diferent metric scores\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    make_scorer,\n",
    ")\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# to split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to build linear regression_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# to check model performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# to build linear regression_model using statsmodels\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "\n",
    "# To build model for prediction\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# To get diferent metric scores\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "# this will help in making the Python code more structured automatically (good coding practice)\n",
    "%load_ext nb_black\n",
    "\n",
    "# Library to suppress warnings or deprecation notes\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library to split data\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    ")\n",
    "\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# Libraries to build decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# To get diferent metric scores\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    "    make_scorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVP = pd.read_csv(\"EVP.csv\")\n",
    "# copying data to another varaible to avoid any changes to original data\n",
    "df = EVP.copy()\n",
    "data = EVP.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-infection",
   "metadata": {
    "id": "desperate-infection"
   },
   "source": [
    "## Data Overview\n",
    "\n",
    "Observations:\n",
    "- There are 25480 records in 25 columns \n",
    "- No negative values\n",
    "- No missing values\n",
    "- All values are numeric\n",
    "- Data is normalized to ensure same scale of comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-calibration",
   "metadata": {
    "id": "seasonal-calibration"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "- EDA is an important part of any project involving data.\n",
    "- It is important to investigate and understand the data better before building a model with it.\n",
    "- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n",
    "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-traveler",
   "metadata": {
    "id": "classified-traveler"
   },
   "source": [
    "**Questions**:\n",
    "1. Those with higher education may want to travel abroad for a well-paid job. Does education play a role in Visa certification? \n",
    "\n",
    "2. How does the visa status vary across different continents? \n",
    " \n",
    "3. Experienced professionals might look abroad for opportunities to improve their lifestyles and career development. Does work experience influence visa status? \n",
    " \n",
    "4. In the United States, employees are paid at different intervals. Which pay unit is most likely to be certified for a visa? \n",
    " \n",
    "5. The US government has established a prevailing wage to protect local talent and foreign workers. How does the visa status change with the prevailing wage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-interference",
   "metadata": {
    "id": "mechanical-interference"
   },
   "outputs": [],
   "source": [
    "# Those with higher education may want to travel abroad for a well-paid job. Does education play a role in Visa certification?\n",
    "# 1. case_status vs. education_of_employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"education_of_employee\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59741964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the visa status vary across different continents?\n",
    "# 2. case_status vs continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"continent\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experienced professionals might look abroad for opportunities to improve their lifestyles and career development. Does work experience influence visa status?\n",
    "# 3. case_status vs has_job_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bfc585",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"has_job_experience\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fa36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the United States, employees are paid at different intervals. Which pay unit is most likely to be certified for a visa?\n",
    "# 4. case_status vs unit_of_wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"unit_of_wage\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc86eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The US government has established a prevailing wage to protect local talent and foreign workers. How does the visa status change with the prevailing wage?\n",
    "# 5. case_status vs prevailing_wage\n",
    "# note- this also can be compared to my annual_value column to see if the annual value of the employee correlates to case status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"prevailing_wage\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6561d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8bea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data, \"continent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb709679",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfb4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c628a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ccae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(data,'fixed acidity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-spirituality",
   "metadata": {
    "id": "alleged-spirituality"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Missing value treatment (if needed)\n",
    "- Feature engineering \n",
    "- Outlier detection and treatment (if needed)\n",
    "- Preparing data for modeling \n",
    "- Any other preprocessing steps (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3676be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d598c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Formatting:\n",
    "# Drop unnecessary\n",
    "# Change to Numeric\n",
    "# Get Dummies\n",
    "# Set as Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unnecessary\n",
    "# checking for missing values\n",
    "df.isnull().sum()\n",
    "# 0 Missisng values\n",
    "# Drop\n",
    "df = df.dropna()\n",
    "# Drop case_id and year_estab\n",
    "df.drop(\"case_id\", axis=1, inplace=True)\n",
    "#\n",
    "df.drop(\"yr_of_estab\", axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5591c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"continent\"].value_counts(dropna=False)\n",
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"education_of_employee\"].value_counts(dropna=False)\n",
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a10ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_job_experience\"].value_counts(dropna=False)\n",
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a05f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"requires_job_training\"].value_counts(dropna=False)\n",
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5aad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"no_of_employees\"].value_counts(dropna=False)\n",
    "# good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ff2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region_of_employment\"].value_counts(dropna=False)\n",
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prevailing_wage\"].value_counts(dropna=False)\n",
    "# No further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a394e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"unit_of_wage\"].value_counts(dropna=False)\n",
    "# Standardize this value\n",
    "# Replace with multiplication factor to standardize at annual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53bfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Unit_of_wage to annual value modifier\n",
    "# In order to deal with difference between yearly salary and hourly, weekly, and monthly, I will create a new column called annual value.\n",
    "\n",
    "\n",
    "def to_annual_value(x):\n",
    "    if x == \"Week\":\n",
    "        return 52\n",
    "    if x == \"Month\":\n",
    "        return 12\n",
    "    if x == \"Hour\":\n",
    "        return 2240\n",
    "    if x == \"Year\":\n",
    "        return 1\n",
    "\n",
    "\n",
    "df[\"annual_value_modifier\"] = df[\"unit_of_wage\"].apply(to_annual_value)\n",
    "# print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a784808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"annual_val\"] = df[\"prevailing_wage\"] * df[\"annual_value_modifier\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop annual_value_modifier and prevailing_wage\n",
    "df.drop(\"annual_value_modifier\", axis=1, inplace=True)\n",
    "#\n",
    "df.drop(\"prevailing_wage\", axis=1, inplace=True)\n",
    "#\n",
    "df.drop(\"unit_of_wage\", axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"full_time_position\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"case_status\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dummies\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\n",
    "        \"continent\",\n",
    "        \"education_of_employee\",\n",
    "        \"has_job_experience\",\n",
    "        \"requires_job_training\",\n",
    "        \"region_of_employment\",\n",
    "        \"full_time_position\",\n",
    "        \"case_status\",\n",
    "    ],\n",
    "    dtype=float,\n",
    ")  # this worked\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735730e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-juice",
   "metadata": {
    "id": "persistent-juice"
   },
   "outputs": [],
   "source": [
    "# Negative number error in number of employees; I didn't have this problem but others complained of negative #s. I assumed a typo; thus I eliminated all possible negatives from this column.\n",
    "df.no_of_employees.abs()\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dcce54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-union",
   "metadata": {
    "id": "difficult-union"
   },
   "source": [
    "## EDA\n",
    "\n",
    "- It is a good idea to explore the data once again after manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-permit",
   "metadata": {
    "id": "right-permit"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee98bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection and treatment (if needed)\n",
    "plt.hist(df[\"weight\"], 20)\n",
    "plt.title(\"Histogram of Weight\")\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(df[\"weight\"])\n",
    "plt.title(\"Boxplot of Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08588e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2235b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c3a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecda66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba465e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7f460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb302180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99f2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "domestic-iceland",
   "metadata": {
    "id": "domestic-iceland"
   },
   "source": [
    "## Building bagging and boosting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-institution",
   "metadata": {
    "id": "unknown-institution"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prime-athletics",
   "metadata": {
    "id": "prime-athletics"
   },
   "source": [
    "##  Will tuning the hyperparameters improve the model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-difficulty",
   "metadata": {
    "id": "banned-difficulty"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "obvious-maine",
   "metadata": {
    "id": "obvious-maine"
   },
   "source": [
    "## Model Performance Comparison and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-kinase",
   "metadata": {
    "id": "everyday-kinase"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nasty-retailer",
   "metadata": {
    "id": "nasty-retailer"
   },
   "source": [
    "## Actionable Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-prediction",
   "metadata": {
    "id": "amino-prediction"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EasyVisa_Project_Template_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
